---
created: 2022-08-29 19:15
updated: 2022-08-29 21:01
---
---
**Links**: [[110 Kubernetes Index]]

---
- We create YAML configuration files for deployments, services and other resources in k8s and then apply them (declarative approach).
- *The configuration file is our desired state. It is kubernetes job to see that the actual state == desired state*.
- Applying a file (creating resources): 
	- `kubectl apply -f deployment.yaml service.yaml`
	
> [!tip]- These files are also known as manifests

> [!note]- If you change anything in the file such as number of replicas or the image then you need to apply the yaml file again.

- Deleting resources:
	- `kubectl delete -f deployment.yaml service.yaml`

- Every configuration file will generally have 5 parts: `apiVersion`, `kind`, `metadata` , `spec` and `status`. 
	- **status is automatically generated by k8s**. k8s gets the current status from etcd.
	- Attributes of `spec` are *specific to the kind of the resource*. 
	- `apiVersion` is different for different component.

## Simple Full Stack App Deployment
- Architecture overview
	- ![[attachments/Pasted image 20220829191505.png]]

- `labels` in metadata
	- In k8s you can give any component a label. 
	- **A label is a key value pair that are attached to the k8s resources**. 
	- We can have anything as key and anything as value for labels.
		- ![[attachments/Pasted image 20220829191843.png]]
	- You can label anything like pod, deployment, services, ConfigMap etc. 
	- Labels are *additional identifiers which are meaningful to the user*.
	- Labels do not provide uniqueness. All pod replicas have the same label. But each pod does have a unique name.
		- ![[attachments/Pasted image 20220829191904.png]]
		- Hence we can identify all the pod replicas of the same application/deployment using a specific label.

> [!note]- **For pods label is a required field**. For other components like config map, deployment etc labels are optional. But it is a good practice to set them.

> [!question]- So when we create pod replicas how does k8s know which pods belong to which deployment?
> ![[attachments/Pasted image 20220829192216.png]]
> - This is defined using `matchLabels`
> - Line 15 and line 11 should be same. Lines 5,6 are optional.
> - You can have any name for key value pairs. Like instead of `app: nginx` you can have `mykey: myvalue`.

- `matchLabels` in selector in service
	- We need a selector in service since it needs to forward the request to a pod. 
	- Now to know which pods to forward this request to we have to use `matchLabels`.
	- ![[attachments/Pasted image 20220829192640.png]]

- Generally in k8s deployment and service configurations are kept in the same yaml file.
	- container port should be same as target port
	- We can have multiple yaml configurations in the same file separated by three dashes(`---`).
	- ![[attachments/Pasted image 20220829192746.png]]

- Sample yaml file which contains both service & deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongo-deployment
  labels:
    app: mongo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
      - name: mongodb
        image: mongo:5.0
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          valueFrom:
            secretKeyRef:
              name: mongo-secret
              key: mongo-user
        - name: MONGO_INITDB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mongo-secret
              key: mongo-password  
---
apiVersion: v1
kind: Service
metadata:
  name: mongo-service
spec:
  selector:
    app: mongo
  ports:
    - protocol: TCP
      port: 27017
      targetPort: 27017
```

- Reference: [Nana Janashia / K8s-in-1-hour Â· GitLab](https://gitlab.com/nanuchi/k8s-in-1-hour)
